import torch
from torch.nn.utils import spectral_norm

from config import (
    latent_dim,
    n_tracks,
    n_measures,
    n_pitches,
    measure_resolution
)
from models.attention.attention import Self_Attn

class DiscriminatorBlock(torch.nn.Module):
    def __init__(self, in_dim, out_dim, kernel, stride):
        super().__init__()
        self.transconv = spectral_norm(torch.nn.Conv3d(in_dim, out_dim, kernel, stride))
    
    def forward(self, x):
        x = self.transconv(x)
        return torch.nn.functional.leaky_relu(x)

class Discriminator(torch.nn.Module):
    """A convolutional neural network (CNN) based discriminator. The
    discriminator takes as input either a real sample (in the training data) or
    a fake sample (generated by the generator) and outputs a scalar indicating
    its authentity.
    """
    def __init__(self):
        super().__init__()
        input_layer = []
        input_layer.append(torch.nn.Linear(13, n_measures*measure_resolution))
        input_layer.append(torch.nn.ReLU())
        input_layer.append(torch.nn.Linear(n_measures*measure_resolution, n_measures*measure_resolution*n_pitches))
        input_layer.append(torch.nn.ReLU())
        input_layer.append(torch.nn.Linear(n_measures*measure_resolution*n_pitches, n_measures*measure_resolution*n_pitches))
        input_layer.append(torch.nn.ReLU())

        self.conv0 = torch.nn.ModuleList([
            DiscriminatorBlock(1, 16, (1, 1, 12), (1, 1, 12)) for _ in range(n_tracks)
        ])
        self.conv1 = torch.nn.ModuleList([
            DiscriminatorBlock(16, 16, (1, 4, 1), (1, 4, 1)) for _ in range(n_tracks)
        ])
        self.conv2 = DiscriminatorBlock(16 * 5, 64, (1, 1, 3), (1, 1, 1))
        self.conv3 = DiscriminatorBlock(64, 64, (1, 1, 4), (1, 1, 4))
        self.conv4 = DiscriminatorBlock(64, 128, (1, 4, 1), (1, 4, 1))
        self.conv5 = DiscriminatorBlock(128, 128, (2, 1, 1), (1, 1, 1))
        self.conv6 = DiscriminatorBlock(128, 256, (3, 1, 1), (3, 1, 1))
        self.dense = torch.nn.Linear(256, 1)

        self.attn1 = Self_Attn(64, 'relu')
        self.attn2 = Self_Attn(128, 'relu')
        self.attn3 = Self_Attn(128, 'relu')
        self.attn4 = Self_Attn(256, 'relu')

        self.input = torch.nn.Sequential(*input_layer)

    def forward(self, x, input):
        input_output = self.input(input)
        input_output = torch.reshape(input_output, (-1, 1, n_measures*measure_resolution, n_pitches))
        x = torch.cat((x, input_output), 1)

        x = x.view(-1, n_tracks+1, n_measures, measure_resolution, n_pitches)
        x = [conv(x[:, [i]]) for i, conv in enumerate(self.conv0)]
        x = torch.cat([conv(x_) for x_, conv in zip(x, self.conv1)], 1)
        x = self.conv2(x)
        x = self.conv3(x)
        x, _ = self.attn1(x)          
        x = self.conv4(x)
        x, _ = self.attn2(x)
        x = self.conv5(x)
        x, _ = self.attn3(x)
        x = self.conv6(x)
        x, _ = self.attn4(x)
        x = x.view(-1, 256)
        x = self.dense(x)
        return x

if __name__ == "__main__":
    input = torch.rand((16, 13))
    latent_vector = torch.randn((16, n_tracks, n_measures*measure_resolution, n_pitches))
    print(latent_vector.shape)
    discriminator = Discriminator()
    x = discriminator(latent_vector, input)
    print(x.shape)
